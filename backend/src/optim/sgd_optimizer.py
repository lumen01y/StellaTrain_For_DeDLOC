import torch
import threading

class SGDOptimizer(torch.nn.Module):
    def __init__(self, lr=0.01, momentum=0, weight_decay=0, dampening=0, 
                 nesterov=False, maximize=False, smart_momentum=False, device="cuda"):
        super(SGDOptimizer, self).__init__()
        self.lr = lr
        self.momentum = momentum
        self.weight_decay = weight_decay
        self.dampening = dampening
        self.nesterov = nesterov
        self.maximize = maximize
        self.smart_momentum = smart_momentum
        self.iteration = 0  # m_iter
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")

        self.lock = threading.Lock()  # C++ mutex ëŒ€ì²´

        # ìƒíƒœ ì €ì¥ (momentum buffer, last update)
        self.momentum_buffer = {}
        self.last_update = {}

    @torch.jit.ignore  # ğŸ”¥ JITì—ì„œ lockì„ ë¬´ì‹œí•˜ë„ë¡ ì²˜ë¦¬
    def acquire_lock(self):
        """ë©€í‹°ìŠ¤ë ˆë“œ ë³´í˜¸ë¥¼ ìœ„í•œ ë½ íšë“"""
        self.lock.acquire()

    @torch.jit.ignore  # ğŸ”¥ JITì—ì„œ lockì„ ë¬´ì‹œí•˜ë„ë¡ ì²˜ë¦¬
    def release_lock(self):
        """ë©€í‹°ìŠ¤ë ˆë“œ ë³´í˜¸ë¥¼ ìœ„í•œ ë½ í•´ì œ"""
        self.lock.release()

    def optimize(self, param: torch.Tensor, name: str, grad_values: torch.Tensor, grad_indices: torch.Tensor):
        """
        PyTorch JIT ì ìš© - ì‹¤í–‰ ì†ë„ ìµœì í™”
        """
        param = param.to(self.device)  # GPUë¡œ ì´ë™
        grad_values = grad_values.to(self.device)
        grad_indices = grad_indices.to(self.device)

        self.acquire_lock()  # ğŸ”¥ ë½ íšë“

        if name not in self.momentum_buffer:
            self.momentum_buffer[name] = torch.zeros_like(param, device=self.device)
            self.last_update[name] = torch.zeros_like(param, dtype=torch.int32, device=self.device)

        # Extract state
        momentum_buf = self.momentum_buffer[name]
        last_update = self.last_update[name]

        # Learning rate ì²˜ë¦¬
        lr = -self.lr if self.maximize else self.lr

        # ì¸ë±ìŠ¤ë¥¼ long íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        grad_indices = grad_indices.long()

        # Gradient ì—…ë°ì´íŠ¸
        for i in range(len(grad_values)):
            idx = grad_indices[i].item()
            grad = grad_values[i].item()

            # Weight Decay ì ìš©
            if self.weight_decay != 0:
                grad += self.weight_decay * param[idx].item()

            # Momentum ê³„ì‚°
            if self.momentum != 0:
                if self.smart_momentum:
                    momentum_factor = self.momentum if self.iteration == 0 else self.momentum ** (self.iteration - last_update[idx].item())
                else:
                    momentum_factor = self.momentum

                if not (0 <= momentum_factor < 1):
                    raise ValueError(f"Invalid momentum {momentum_factor}")

                if self.iteration == 0:
                    momentum_buf[idx] = grad
                else:
                    momentum_buf[idx] = momentum_factor * momentum_buf[idx] + (1 - self.dampening) * grad

                if self.nesterov:
                    grad += momentum_factor * momentum_buf[idx]
                else:
                    grad = momentum_buf[idx]

            # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
            param[idx] -= lr * grad

            # Smart Momentumì„ ìœ„í•œ ì—…ë°ì´íŠ¸ íƒ€ì´ë° ì €ì¥
            if self.smart_momentum:
                last_update[idx] = self.iteration

        self.iteration += 1
        self.release_lock()  # ğŸ”¥ ë½ í•´ì œ

    def configure(self, option_name, option_value):
        """
        Optimizer í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        """
        if option_name == "lr":
            self.lr = option_value
        elif option_name == "momentum":
            self.momentum = option_value
        elif option_name == "weight_decay":
            self.weight_decay = option_value
        elif option_name == "dampening":
            self.dampening = option_value
        elif option_name == "nesterov":
            self.nesterov = option_value
        elif option_name == "maximize":
            self.maximize = option_value
        elif option_name == "smart_momentum":
            self.smart_momentum = option_value
        else:
            raise ValueError(f"Unknown option: {option_name}")

# `torch.compile()`ì„ ì ìš©í•˜ì—¬ PyTorch ë‚´ë¶€ ìµœì í™” í™œì„±í™”
SGDOptimizer = torch.compile(SGDOptimizer)
